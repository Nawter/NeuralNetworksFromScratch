{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "#Import Code from previous videos:\n",
    "from partFour import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalGradient = (f(x+epsilon)- f(x-epsilon))/(2*epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.9999999999996696, 3.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericalGradient, 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = 2\n",
    "        self.outputLayerSize = 1\n",
    "        self.hiddenLayerSize = 3\n",
    "        #Weights(parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize, self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize, self.outputLayerSize)\n",
    "\n",
    "    def forward(self, I):\n",
    "        #Propagate inputs through network\n",
    "        self.z2 = np.dot(I, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        jHat = self.sigmoid(self.z3)\n",
    "        return jHat\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "## --------------------- Part 3 --------------------\n",
    "    #Gradient of sigmoid\n",
    "    def sigmoidPrime(self,z):\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "\n",
    "    #Compute cost for given I,j, use weights already stored in class.\n",
    "    def costFunction(self, I, j):\n",
    "        self.jHat = self.forward(I)\n",
    "        J = 0.5*sum((j-self.jHat)**2)\n",
    "        return J\n",
    "\n",
    "    #Compute derivative with respect to W1 and W2 for a given I and j:\n",
    "    def costFunctionPrime(self, I, j):\n",
    "        self.jHat = self.forward(I)\n",
    "        delta3 = np.multiply(-(j-self.jHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "\n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(I.T, delta2)\n",
    "\n",
    "        return dJdW1, dJdW2\n",
    "## --------------------- Part 4 --------------------\n",
    "# Helper methods to interact with other methods\n",
    "    # Get W1 and W2 unrolled into vector:\n",
    "    def getParams(self):\n",
    "        parameters = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return parameters\n",
    "\n",
    "    # Set W1 and W2 using single parameter vector\n",
    "    def setParams(self, parameters):\n",
    "        w1Start = 0\n",
    "        w1End = self.hiddenLayerSize * self.inputLayerSize\n",
    "        self.W1 = np.reshape(parameters[w1Start:w1End], (self.inputLayerSize, self.hiddenLayerSize))\n",
    "        w2End = w1End + self.hiddenLayerSize * self.outputLayerSize\n",
    "        self.W2 = np.reshape(parameters[w1End:w2End], (self.hiddenLayerSize, self.outputLayerSize))\n",
    "\n",
    "\n",
    "    def computeGradients(self, I, j):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(I, j)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Numerical Gradient</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeNumericalGradient(N, I, j):\n",
    "    paramsInitial = N.getParams()\n",
    "    numgrad = np.zeros(paramsInitial.shape)\n",
    "    perturb = np.zeros(paramsInitial.shape)\n",
    "    e = 1e-4\n",
    "\n",
    "    for p in range(len(paramsInitial)):\n",
    "        #Set perturbation vector\n",
    "        perturb[p] = e\n",
    "        N.setParams(paramsInitial + perturb)\n",
    "        loss2 = N.costFunction(I, j)\n",
    "\n",
    "        N.setParams(paramsInitial - perturb)\n",
    "        loss1 = N.costFunction(I, j)\n",
    "\n",
    "        #Compute numerical gradient\n",
    "        numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "\n",
    "        #Return the value we changed to zeros\n",
    "        perturb[p] = 0\n",
    "\n",
    "    #Return params to original value\n",
    "    N.setParams(paramsInitial)\n",
    "\n",
    "    return numgrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalGradient = computeNumericalGradient(NN, I, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02334972,  0.0096146 ,  0.00378851, -0.01433636,  0.00570024,\n",
       "        0.00204471, -0.04832328, -0.04326428, -0.01234508])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericalGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient = NN.computeGradients(I,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02334972,  0.0096146 ,  0.00378851, -0.01433636,  0.00570024,\n",
       "        0.00204471, -0.04832328, -0.04326428, -0.01234508])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0724558095011934e-09"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(grad-numgrad)/np.linalg.norm(grad+numgrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
